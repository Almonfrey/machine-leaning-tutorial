{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials, early_stop\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates a tf.Dataset generator\n",
    "def create_tf_dataset(X, y, batch_size):\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.shuffle(seed=42, buffer_size=len(X)).batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Train the model\n",
    "def train_model(params):\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    # Split train to have the validation set\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # put data in a tf.Dataset pipeline\n",
    "    train_data = create_tf_dataset(X_train, y_train, params['batch_size'])\n",
    "    eval_data = create_tf_dataset(X_eval, y_eval, params['batch_size'])\n",
    "\n",
    "    # Build MLP model with given hyperparameters\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        Dense(\n",
    "            params['layer_sizes'][0], \n",
    "            activation=params['activation']\n",
    "        ),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=params['learn_rate']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=5, verbose=0)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=params['epochs'],\n",
    "        validation_data=eval_data,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Get the last iteration validation loss as hyperopt score\n",
    "    eval_score = history.history[\"val_loss\"][-1]\n",
    "    \n",
    "    return {\n",
    "        'loss': eval_score,\n",
    "        'status': hyperopt.STATUS_OK,\n",
    "    }\n",
    "\n",
    "# Objective function to minimize (negative accuracy)\n",
    "def objective(params):\n",
    "    return train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for hyperparameters\n",
    "space = {\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'epochs': hp.choice('epochs', [5, 10, 20]),\n",
    "    'layer_sizes': hp.choice('layer_sizes', [(64,), (128,), (256,)]),\n",
    "    'activation': hp.choice('activation', ['relu', 'tanh']),\n",
    "    'learn_rate': hp.loguniform('learn_rate', -5, 0)\n",
    "}\n",
    "\n",
    "# Perform hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, \n",
    "            algo=tpe.suggest, max_evals=50, \n",
    "            trials=trials, rstate=np.random.default_rng(42),\n",
    "            early_stop_fn=early_stop.no_progress_loss(5)\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(hyperopt.space_eval(space, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
